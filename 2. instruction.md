# Project Overview
GPT Telegram bot which can work with text, images and voice (all of these can be input and output)


# Core functionalities
## 1. Bot should support openai streaming mode
## 2. Bot can be added into telegram groups
## 3. There should be a settings panel, so one can edit 
the following parameters for text model:
-- base url of openai compatible model
-- model itself (either chose from the short list of 4 most popular openai models or enter manually the name of the model)
-- temperature (from 0 to 1, of possible use progress bar or something like this)
-- max tokens (from 150 till infinity)
-- There should be an option to use for text messages a pre-configured AI-assitant by providing uri of API end point. This should be instead of a GPT text model. When user choses AI-assitant in GPT text model settings it should overwrite GPT text model settings and all text questions should be handled by AI-assitant via API end point provided.
## 4. There should be a settings panel, so one can edit 
the following parameters for images model:
-- base url of openai compatible image model
-- model itself (either chose from the short list of most popular openai image models or enter manually the name of the model)
-- all Key Parameters and Features of image model
## 5. There should be a settings panel, so one can edit 
the following parameters for voice model:
-- base url of openai compatible voice model
-- model itself (either chose from the short list of most popular openai voice models or enter manually the name of the model)
-- all Key Parameters and Features of voice model
## 6. Bot should support user id's and can store user message history
## 7. There should be an option to clear message history for a user


# Documentation
## requirements file example
```
python-telegram-bot==20.8
python-dotenv==1.0.0
openai==1.12.0
```
## How to enhance the config to include all model settings:
```
from dotenv import load_dotenv
import os
from dataclasses import dataclass

@dataclass
class ModelSettings:
    base_url: str
    model_name: str
    temperature: float = 0.7
    max_tokens: int = 1000

class Config:
    load_dotenv()
    
    # API Keys
    TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    
    # Default settings
    TEXT_MODEL = ModelSettings(
        base_url="https://api.openai.com/v1",
        model_name="gpt-3.5-turbo"
    )
    
    IMAGE_MODEL = ModelSettings(
        base_url="https://api.openai.com/v1",
        model_name="dall-e-3"
    )
    
    VOICE_MODEL = ModelSettings(
        base_url="https://api.openai.com/v1",
        model_name="whisper-1"
    )
    
    # Menu options in Russian
    MENU_OPTIONS = {
        "settings": "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸",
        "clear_history": "ĞÑ‡Ğ¸ÑÑ‚Ğ¸Ñ‚ÑŒ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ",
        "help": "ĞŸĞ¾Ğ¼Ğ¾Ñ‰ÑŒ",
        "text_settings": "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸",
        "image_settings": "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹",
        "voice_settings": "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸"
    }
```

## here's how to implement streaming with OpenAI:
```
async def stream_openai_response(client, messages, model="gpt-3.5-turbo"):
    try:
        stream = await client.chat.completions.create(
            model=model,
            messages=messages,
            stream=True
        )
        
        async for chunk in stream:
            if chunk.choices[0].delta.content:
                yield chunk.choices[0].delta.content
                
    except Exception as e:
        yield f"Error: {str(e)}"
```

## Here's how to handle streaming updates in Telegram:
```
async def handle_streaming_message(update, context):
    # Send initial response
    response_message = await update.message.reply_text("...")
    collected_response = []
    
    async def update_message(new_chunk):
        collected_response.append(new_chunk)
        # Update message every few chunks to avoid rate limits
        if len(collected_response) % 3 == 0:
            await response_message.edit_text("".join(collected_response))
    
    # Use the stream
    async for chunk in stream_openai_response(client, messages):
        await update_message(chunk)
    
    # Final update
    await response_message.edit_text("".join(collected_response))
```
## Example of message history management:
```
class MessageHistory:
    def __init__(self, max_messages=10):
        self.history = {}  # user_id -> messages list
        self.max_messages = max_messages

    def add_message(self, user_id: int, role: str, content: str):
        if user_id not in self.history:
            self.history[user_id] = []
            
        self.history[user_id].append({
            "role": role,
            "content": content
        })
        
        # Trim history if too long
        if len(self.history[user_id]) > self.max_messages:
            self.history[user_id] = self.history[user_id][-self.max_messages:]

    def get_history(self, user_id: int) -> list:
        return self.history.get(user_id, [])

    def clear_history(self, user_id: int):
        self.history[user_id] = []
```

## Example of handling different message types:
```
async def process_message(update, context, history):
    user_id = update.effective_user.id
    message = update.message
    
    if message.text:
        # Handle text message
        history.add_message(user_id, "user", message.text)
        return await handle_streaming_message(update, context)
        
    elif message.voice:
        # Placeholder for voice handling
        await message.reply_text("Ğ“Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²Ñ‹Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ĞºĞ° Ğ½Ğµ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ÑÑ‚ÑÑ")
        
    elif message.photo:
        # Placeholder for image handling
        await message.reply_text("ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¿Ğ¾ĞºĞ° Ğ½Ğµ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚ÑÑ")
```
## Main Settings
â”œâ”€â”€ Text Settings
â”‚   â”œâ”€â”€ Model Selection
â”‚   â”œâ”€â”€ Temperature
â”‚   â”œâ”€â”€ Max Tokens
â”‚   â””â”€â”€ AI Assistant Toggle
â”œâ”€â”€ Image Settings
â”‚   â”œâ”€â”€ Model Selection
â”‚   â”œâ”€â”€ Size
â”‚   â”œâ”€â”€ Quality
â”‚   â””â”€â”€ Style
â””â”€â”€ Voice Settings
    â”œâ”€â”€ TTS Model
    â”œâ”€â”€ STT Model
    â”œâ”€â”€ Voice Type
    â””â”€â”€ Speed

# Project files structure
ğŸ“ gpt-telegram-bot/
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ bot.py              # Main bot implementation + handlers
â”‚   â”œâ”€â”€ models.py           # All model integrations (text, image, voice)
â”‚   â”œâ”€â”€ services.py         # History management + AI Assistant integration
â”‚   â””â”€â”€ config.py           # Settings, constants, and configuration
â”‚
â”œâ”€â”€ ğŸ“ tests/              
â”‚   â””â”€â”€ test_bot.py        # All tests
â”‚
â”œâ”€â”€ .env                    # Environment variables and API keys
â”œâ”€â”€ requirements.txt        # Project dependencies
â””â”€â”€ README.md              # Documentation and setup instructions
